{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "bert_qna.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09bf48ecd9234e3bafc7f95624bc6724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2d61e3e52f54e9589874749cf8c9332",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_543bb8f3d706401a913924d1c182e195",
              "IPY_MODEL_0255b67c5bde41ec8e09d80b894c42f8",
              "IPY_MODEL_3870a0866a8b41ad87a83c42989e461b"
            ]
          }
        },
        "b2d61e3e52f54e9589874749cf8c9332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "543bb8f3d706401a913924d1c182e195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b891a20d9a5b436aad05da370269b3c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b237ffefe4d7460f973baf9bf6fe1b52"
          }
        },
        "0255b67c5bde41ec8e09d80b894c42f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_65f63ae87df84c83840703ec7c72f441",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1420,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1420,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83f916c76ff1442294d42e453d7b9f82"
          }
        },
        "3870a0866a8b41ad87a83c42989e461b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e49d562acf964356bade364c1eabe63f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1420/1420 [00:33&lt;00:00, 19.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c50fb7b11d084378a8f2d056991d4b73"
          }
        },
        "b891a20d9a5b436aad05da370269b3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b237ffefe4d7460f973baf9bf6fe1b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65f63ae87df84c83840703ec7c72f441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83f916c76ff1442294d42e453d7b9f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e49d562acf964356bade364c1eabe63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c50fb7b11d084378a8f2d056991d4b73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8a563176d074e7fbb07758750df61f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bdd623baa8fc45b0bb6141cab1e08438",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_99aef07f7ba2406bbfcbe56ba9d347d0",
              "IPY_MODEL_54bbd99e6d0f4fd69ed433052c41f98e",
              "IPY_MODEL_98f1fcf1fe2e4cf2a2733e40266034a2"
            ]
          }
        },
        "bdd623baa8fc45b0bb6141cab1e08438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99aef07f7ba2406bbfcbe56ba9d347d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b1a70922aa142c093cbad08a2cb2e2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9b697bf6233400280bd020d813aaf6b"
          }
        },
        "54bbd99e6d0f4fd69ed433052c41f98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa7190897cdf4686a954a21f11af8277",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 140,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 140,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6eb7cf55abd43ff8c301dbfdfbf14dc"
          }
        },
        "98f1fcf1fe2e4cf2a2733e40266034a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27a4155c3baa4fc7b5af5969d2aba76b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 140/140 [00:03&lt;00:00, 37.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dde1daddeef441ccb2c0b408f7a5ae80"
          }
        },
        "3b1a70922aa142c093cbad08a2cb2e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9b697bf6233400280bd020d813aaf6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa7190897cdf4686a954a21f11af8277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6eb7cf55abd43ff8c301dbfdfbf14dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27a4155c3baa4fc7b5af5969d2aba76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dde1daddeef441ccb2c0b408f7a5ae80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceb0d171f22b4d15b96e4445a24cdc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffb83fe80bbd4e0caad087d46f508587",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b966a48954584434b0912027f54470b6",
              "IPY_MODEL_3c047b01c82a4ba79d732a855fd2dfe5",
              "IPY_MODEL_15e59c121cf240fcbbfc595752da61db"
            ]
          }
        },
        "ffb83fe80bbd4e0caad087d46f508587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b966a48954584434b0912027f54470b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9f5ad2148d74c34ad1a6b879462886c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Loading ...: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55d39ae533dd4b199d341024849a2f97"
          }
        },
        "3c047b01c82a4ba79d732a855fd2dfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26a0779e6b994270bcca71d6c068ac5f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99ad4927a092484892e08b41476af76f"
          }
        },
        "15e59c121cf240fcbbfc595752da61db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4125c2e95ee34e7b98de765661604845",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60407/? [00:21&lt;00:00, 2450.87it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec710512ddde4f56b41d3e458ffd6875"
          }
        },
        "d9f5ad2148d74c34ad1a6b879462886c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55d39ae533dd4b199d341024849a2f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26a0779e6b994270bcca71d6c068ac5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99ad4927a092484892e08b41476af76f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4125c2e95ee34e7b98de765661604845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec710512ddde4f56b41d3e458ffd6875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4ccdae174e545d69225ce8be22d4b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74751792adaa4018ae7c0990049457ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_480936bb08644d45965079ab5927fdbc",
              "IPY_MODEL_b8ecf1afbc4642a69e9888e27e4c3c06",
              "IPY_MODEL_138323405ea742808e30f90c1a3b1898"
            ]
          }
        },
        "74751792adaa4018ae7c0990049457ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "480936bb08644d45965079ab5927fdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_596ed639b9114d5489cc66bfeb4859f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Loading ...: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09f48d4d5dd942788e43f3956408b072"
          }
        },
        "b8ecf1afbc4642a69e9888e27e4c3c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ceee1845c3c347c0a3ead7bdea4f4eea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4543e38dcc304df680046556725b4418"
          }
        },
        "138323405ea742808e30f90c1a3b1898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d85bbb72f1e04593bd7118fb827afea8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5774/? [00:02&lt;00:00, 2873.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af0c2ce3807a49e09631d37438558655"
          }
        },
        "596ed639b9114d5489cc66bfeb4859f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09f48d4d5dd942788e43f3956408b072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceee1845c3c347c0a3ead7bdea4f4eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4543e38dcc304df680046556725b4418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d85bbb72f1e04593bd7118fb827afea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af0c2ce3807a49e09631d37438558655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d29ad379512f46edab9d9656ad8a6d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e946348b1c9a4844a12e26e8327da904",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2c8069f0fed4bf99c33cc9263021fea",
              "IPY_MODEL_a997337ceaab4994968b68cf0e82f7df",
              "IPY_MODEL_2def78c56616487e878bf470b8befbc4"
            ]
          }
        },
        "e946348b1c9a4844a12e26e8327da904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2c8069f0fed4bf99c33cc9263021fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22054c1667c249ae99205a8d8167ae08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "loss: 4.2234, 4.7232, acc: 0.0682, 0.0539:  49%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c00567f2bf94439bb55b6f9fc2bd589e"
          }
        },
        "a997337ceaab4994968b68cf0e82f7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61c7ace3ed414e5ca9712a210d6401c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1875,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 920,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6edd0e956edb4fc5bbf35d50b551da70"
          }
        },
        "2def78c56616487e878bf470b8befbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_207e817a7b6f46bda092f98ce2a27a11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 920/1875 [05:25&lt;05:39,  2.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_036c2d8fb316473aba8bbfc07ad39de4"
          }
        },
        "22054c1667c249ae99205a8d8167ae08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c00567f2bf94439bb55b6f9fc2bd589e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61c7ace3ed414e5ca9712a210d6401c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6edd0e956edb4fc5bbf35d50b551da70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "207e817a7b6f46bda092f98ce2a27a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "036c2d8fb316473aba8bbfc07ad39de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bupark82/crossword_project/blob/master/bert_qna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXq7IGO4b0pM",
        "outputId": "f8b43912-3017-40ac-f572-5d14feb387c4"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3sl_lP1lUGu"
      },
      "source": [
        "# import sys\n",
        "# print(sys.getdefaultencoding())\n",
        "# print(sys.stdin.encoding)\n",
        "# print(sys.stdout.encoding)\n",
        "# import locale\n",
        "# print(locale.getpreferredencoding())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTBIq-q0dj89",
        "outputId": "344f4660-6a7e-47cc-b3f6-a19bf6e224b7"
      },
      "source": [
        "# 구글드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "# 구글 드라이브 파일 확인\n",
        "!ls '/gdrive/My Drive/team38/'\n",
        "\n",
        "# 반복되는 드라이브 경로 변수화\n",
        "drive_path = '/gdrive/My Drive/team38/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "bert_qna  crossword_project  data  Model.ipynb\tModel_origin.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWfWoKiQeSf0",
        "outputId": "4814d3aa-49f3-4805-862b-b389c6657bf8"
      },
      "source": [
        "!pip install tensorflow_addons==0.11.2\n",
        "!pip install sentencepiece\n",
        "!pip install wordcloud\n",
        "!pip install ipywidgets --user\n",
        "!pip install tqdm\n",
        "!pip install pydot\n",
        "!pip install pydotplus\n",
        "# !pip install graphviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons==0.11.2 in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons==0.11.2) (2.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.5)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.2)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot) (2.4.7)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pydotplus) (2.4.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8UEkaW3b0pP"
      },
      "source": [
        "# imports\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "import collections\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import sentencepiece as spm\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "random_seed = 1234\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYux9IpRb0pQ"
      },
      "source": [
        "def print_json_tree(data, indent=\"\"):\n",
        "    for key, value in data.items():\n",
        "        if type(value) == list:     # list 형태의 item은 첫번째 item만 출력\n",
        "            print(f'{indent}- {key}: [{len(value)}]')\n",
        "            print_json_tree(value[0], indent + \"  \")\n",
        "        else:\n",
        "            print(f'{indent}- {key}: {value}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uvat7-Ab0pR",
        "outputId": "8679460f-57b1-4e7f-ae68-3ac4fcbded1e"
      },
      "source": [
        "data_dir = '/gdrive/MyDrive/team38/bert_qna/data' # /gdrive/MyDrive/team38/bert_qna/data\n",
        "model_dir = '/gdrive/MyDrive/team38/bert_qna/models' # /gdrive/MyDrive/team38/bert_qna/models\n",
        "\n",
        "# 훈련데이터 확인\n",
        "train_json_path = data_dir + '/KorQuAD_v1.0_train.json'\n",
        "with open(train_json_path) as f:\n",
        "    train_json = json.load(f)\n",
        "    print_json_tree(train_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- version: KorQuAD_v1.0_train\n",
            "- data: [1420]\n",
            "  - paragraphs: [3]\n",
            "    - qas: [8]\n",
            "      - answers: [1]\n",
            "        - text: 교향곡\n",
            "        - answer_start: 54\n",
            "      - id: 6566495-0-0\n",
            "      - question: 바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
            "    - context: 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
            "  - title: 파우스트_서곡\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmeMEe3xb0pR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd8ab56-baf9-4a1c-a89c-a60f2e5ead5c"
      },
      "source": [
        "# 검증데이터 확인\n",
        "dev_json_path = data_dir + '/KorQuAD_v1.0_dev.json'\n",
        "with open(dev_json_path) as f:\n",
        "    dev_json = json.load(f)\n",
        "    print_json_tree(dev_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- version: KorQuAD_v1.0_dev\n",
            "- data: [140]\n",
            "  - paragraphs: [2]\n",
            "    - qas: [7]\n",
            "      - answers: [1]\n",
            "        - text: 1989년 2월 15일\n",
            "        - answer_start: 0\n",
            "      - id: 6548850-0-0\n",
            "      - question: 임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
            "    - context: 1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
            "  - title: 임종석\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_eZpIfVb0pR"
      },
      "source": [
        "## KorQuAD 데이터셋 전처리 (1) 띄어쓰기 단위 정보관리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Q2Cg4Tb0pS"
      },
      "source": [
        "def _is_whitespace(c):\n",
        "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZxb1Da9b0pT"
      },
      "source": [
        "def _tokenize_whitespace(string):\n",
        "    word_tokens = []\n",
        "    char_to_word = []\n",
        "    prev_is_whitespace = True\n",
        "\n",
        "    for c in string:\n",
        "        if _is_whitespace(c):\n",
        "            prev_is_whitespace = True\n",
        "        else:\n",
        "            if prev_is_whitespace:\n",
        "                word_tokens.append(c)\n",
        "            else:\n",
        "                word_tokens[-1] += c\n",
        "            prev_is_whitespace = False    \n",
        "        char_to_word.append(len(word_tokens) - 1)\n",
        "    \n",
        "    return word_tokens, char_to_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jJk5_REb0pU"
      },
      "source": [
        "## KorQuAD 데이터셋 전처리 (2) Tokenize by Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YpOS_C8b0pU"
      },
      "source": [
        "def _tokenize_vocab(vocab, context_words):\n",
        "    word_to_token = []\n",
        "    context_tokens = []\n",
        "    for (i, word) in enumerate(context_words):\n",
        "        word_to_token.append(len(context_tokens))\n",
        "        tokens = vocab.encode_as_pieces(word)\n",
        "        for token in tokens:\n",
        "            context_tokens.append(token)\n",
        "    return context_tokens, word_to_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU7rUo-wb0pU"
      },
      "source": [
        "## KorQuAD 데이터셋 전처리 (3) Improve Span"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2JK1gGdb0pV"
      },
      "source": [
        "# context_tokens에서 char_answer의 위치를 찾아 리턴하는 함수\n",
        "def _improve_span(vocab, context_tokens, token_start, token_end, char_answer):\n",
        "    token_answer = \" \".join(vocab.encode_as_pieces(char_answer))\n",
        "    for new_start in range(token_start, token_end + 1):\n",
        "        for new_end in range(token_end, new_start - 1, -1):\n",
        "            text_span = \" \".join(context_tokens[new_start : (new_end + 1)])\n",
        "            if text_span == token_answer:\n",
        "                return (new_start, new_end)\n",
        "    return (token_start, token_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU3FHxADb0pV"
      },
      "source": [
        "## KorQuAD 데이터셋 전처리 (4) 데이터셋 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWp2Zm0Rb0pV"
      },
      "source": [
        "def dump_korquad(vocab, json_data, out_file):\n",
        "    with open(out_file, \"w\") as f:\n",
        "        for data in tqdm(json_data[\"data\"]):\n",
        "            title = data[\"title\"]\n",
        "            for paragraph in data[\"paragraphs\"]:\n",
        "                context = paragraph[\"context\"]\n",
        "                context_words, char_to_word = _tokenize_whitespace(context)\n",
        "\n",
        "                for qa in paragraph[\"qas\"]:\n",
        "                    assert len(qa[\"answers\"]) == 1\n",
        "                    qa_id = qa[\"id\"]\n",
        "                    question = qa[\"question\"]\n",
        "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                    answer_start = qa[\"answers\"][0][\"answer_start\"]\n",
        "                    answer_end = answer_start + len(answer_text) - 1\n",
        "\n",
        "                    assert answer_text == context[answer_start:answer_end + 1]\n",
        "\n",
        "                    word_start = char_to_word[answer_start]\n",
        "                    word_end = char_to_word[answer_end]\n",
        "\n",
        "                    word_answer = \" \".join(context_words[word_start:word_end + 1])\n",
        "                    char_answer = \" \".join(answer_text.strip().split())\n",
        "                    assert char_answer in word_answer\n",
        "\n",
        "                    context_tokens, word_to_token = _tokenize_vocab(vocab, context_words)\n",
        "\n",
        "                    token_start = word_to_token[word_start]\n",
        "                    if word_end < len(word_to_token) - 1:\n",
        "                        token_end = word_to_token[word_end + 1] - 1\n",
        "                    else:\n",
        "                        token_end = len(context_tokens) - 1\n",
        "\n",
        "                    token_start, token_end = _improve_span(vocab, context_tokens, token_start, token_end, char_answer)\n",
        "\n",
        "                    data = {\"qa_id\": qa_id, \"title\": title, \"question\": vocab.encode_as_pieces(question), \"context\": context_tokens, \"answer\": char_answer, \"token_start\": token_start, \"token_end\":token_end}\n",
        "                    f.write(json.dumps(data, ensure_ascii=False))\n",
        "                    f.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAkRAOLqhHeL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "09bf48ecd9234e3bafc7f95624bc6724",
            "b2d61e3e52f54e9589874749cf8c9332",
            "543bb8f3d706401a913924d1c182e195",
            "0255b67c5bde41ec8e09d80b894c42f8",
            "3870a0866a8b41ad87a83c42989e461b",
            "b891a20d9a5b436aad05da370269b3c4",
            "b237ffefe4d7460f973baf9bf6fe1b52",
            "65f63ae87df84c83840703ec7c72f441",
            "83f916c76ff1442294d42e453d7b9f82",
            "e49d562acf964356bade364c1eabe63f",
            "c50fb7b11d084378a8f2d056991d4b73",
            "a8a563176d074e7fbb07758750df61f2",
            "bdd623baa8fc45b0bb6141cab1e08438",
            "99aef07f7ba2406bbfcbe56ba9d347d0",
            "54bbd99e6d0f4fd69ed433052c41f98e",
            "98f1fcf1fe2e4cf2a2733e40266034a2",
            "3b1a70922aa142c093cbad08a2cb2e2d",
            "c9b697bf6233400280bd020d813aaf6b",
            "aa7190897cdf4686a954a21f11af8277",
            "f6eb7cf55abd43ff8c301dbfdfbf14dc",
            "27a4155c3baa4fc7b5af5969d2aba76b",
            "dde1daddeef441ccb2c0b408f7a5ae80"
          ]
        },
        "outputId": "9b7780e2-fcf7-4d74-8b63-9a06675a45aa"
      },
      "source": [
        "# 전처리를 수행하여 파일로 생성합니다. \n",
        "dump_korquad(vocab, train_json, f\"{data_dir}/korquad_train.json\")\n",
        "dump_korquad(vocab, dev_json, f\"{data_dir}/korquad_dev.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09bf48ecd9234e3bafc7f95624bc6724",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1420 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8a563176d074e7fbb07758750df61f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/140 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzi75uCtb0pW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4085b990-24ca-47d6-995e-77319dde5ead"
      },
      "source": [
        "# vocab loading\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(f\"{model_dir}/ko_32000.model\")\n",
        "\n",
        "# # word를 subword로 변경하면서 index 저장\n",
        "# word_to_token = []\n",
        "# context_tokens = []\n",
        "# for (i, word) in enumerate(word_tokens):\n",
        "#     word_to_token.append(len(context_tokens))\n",
        "#     tokens = vocab.encode_as_pieces(word)  # SentencePiece를 사용해 Subword로 쪼갭니다.\n",
        "#     for token in tokens:\n",
        "#         context_tokens.append(token)\n",
        "\n",
        "# context_tokens, word_to_token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTBqyrejb0pW"
      },
      "source": [
        "def print_file(filename, count=10):\n",
        "    \"\"\"\n",
        "    파일 내용 출력\n",
        "    :param filename: 파일 이름\n",
        "    :param count: 출력 라인 수\n",
        "    \"\"\"\n",
        "    with open(filename) as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if count <= i:\n",
        "                break\n",
        "            print(line.strip())\n",
        "\n",
        "# print_file(f\"{data_dir}/korquad_train.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY5Mb9xeb0pW"
      },
      "source": [
        "## KorQuAD 데이터셋 전처리 (9) 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSB-pkPob0pW"
      },
      "source": [
        "train_json = os.path.join(data_dir, \"korquad_train.json\")\n",
        "dev_json = os.path.join(data_dir, \"korquad_dev.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfBRh7uUb0pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0ccd0d-43e0-491b-a9a2-fcacc5dbffa5"
      },
      "source": [
        "class Config(dict):\n",
        "    \"\"\"\n",
        "    json을 config 형태로 사용하기 위한 Class\n",
        "    :param dict: config dictionary\n",
        "    \"\"\"\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "\n",
        "args = Config({\n",
        "    'max_seq_length': 384,\n",
        "    'max_query_length': 64,\n",
        "})\n",
        "args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_query_length': 64, 'max_seq_length': 384}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "618uKnllb0pX"
      },
      "source": [
        "# 생성한 데이터셋 파일을 메모리에 로딩하는 함수\n",
        "def load_data(args, filename):\n",
        "    inputs, segments, labels_start, labels_end = [], [], [], []\n",
        "\n",
        "    n_discard = 0\n",
        "    with open(filename, \"r\") as f:\n",
        "        for i, line in enumerate(tqdm(f, desc=f\"Loading ...\")):\n",
        "            data = json.loads(line)\n",
        "            token_start = data.get(\"token_start\")\n",
        "            token_end = data.get(\"token_end\")\n",
        "            question = data[\"question\"][:args.max_query_length]\n",
        "            context = data[\"context\"]\n",
        "            answer_tokens = \" \".join(context[token_start:token_end + 1])\n",
        "            context_len = args.max_seq_length - len(question) - 3\n",
        "\n",
        "            if token_end >= context_len:\n",
        "                # 최대 길이내에 token이 들어가지 않은 경우 처리하지 않음\n",
        "                n_discard += 1\n",
        "                continue\n",
        "            context = context[:context_len]\n",
        "            assert len(question) + len(context) <= args.max_seq_length - 3\n",
        "\n",
        "            tokens = ['[CLS]'] + question + ['[SEP]'] + context + ['[SEP]']\n",
        "            ids = [vocab.piece_to_id(token) for token in tokens]\n",
        "            ids += [0] * (args.max_seq_length - len(ids))\n",
        "            inputs.append(ids)\n",
        "            segs = [0] * (len(question) + 2) + [1] * (len(context) + 1)\n",
        "            segs += [0] * (args.max_seq_length - len(segs))\n",
        "            segments.append(segs)\n",
        "            token_start += (len(question) + 2)\n",
        "            labels_start.append(token_start)\n",
        "            token_end += (len(question) + 2)\n",
        "            labels_end.append(token_end)\n",
        "    print(f'n_discard: {n_discard}')\n",
        "\n",
        "    return (np.array(inputs), np.array(segments)), (np.array(labels_start), np.array(labels_end))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtnxJKUDb0pX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "ceb0d171f22b4d15b96e4445a24cdc2a",
            "ffb83fe80bbd4e0caad087d46f508587",
            "b966a48954584434b0912027f54470b6",
            "3c047b01c82a4ba79d732a855fd2dfe5",
            "15e59c121cf240fcbbfc595752da61db",
            "d9f5ad2148d74c34ad1a6b879462886c",
            "55d39ae533dd4b199d341024849a2f97",
            "26a0779e6b994270bcca71d6c068ac5f",
            "99ad4927a092484892e08b41476af76f",
            "4125c2e95ee34e7b98de765661604845",
            "ec710512ddde4f56b41d3e458ffd6875",
            "d4ccdae174e545d69225ce8be22d4b53",
            "74751792adaa4018ae7c0990049457ea",
            "480936bb08644d45965079ab5927fdbc",
            "b8ecf1afbc4642a69e9888e27e4c3c06",
            "138323405ea742808e30f90c1a3b1898",
            "596ed639b9114d5489cc66bfeb4859f8",
            "09f48d4d5dd942788e43f3956408b072",
            "ceee1845c3c347c0a3ead7bdea4f4eea",
            "4543e38dcc304df680046556725b4418",
            "d85bbb72f1e04593bd7118fb827afea8",
            "af0c2ce3807a49e09631d37438558655"
          ]
        },
        "outputId": "f0065485-14c8-4568-ce08-65561efa0ea9"
      },
      "source": [
        "# train data load\n",
        "train_inputs, train_labels = load_data(args, train_json)\n",
        "print(f\"train_inputs: {train_inputs[0].shape}\")\n",
        "print(f\"train_inputs: {train_inputs[1].shape}\")\n",
        "print(f\"train_labels: {train_labels[0].shape}\")\n",
        "print(f\"train_labels: {train_labels[1].shape}\")\n",
        "\n",
        "# dev data load\n",
        "dev_inputs, dev_labels = load_data(args, dev_json)\n",
        "print(f\"dev_inputs: {dev_inputs[0].shape}\")\n",
        "print(f\"dev_inputs: {dev_inputs[1].shape}\")\n",
        "print(f\"dev_labels: {dev_labels[0].shape}\")\n",
        "print(f\"dev_labels: {dev_labels[1].shape}\")\n",
        "\n",
        "train_inputs[:10], train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceb0d171f22b4d15b96e4445a24cdc2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Loading ...: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_discard: 430\n",
            "train_inputs: (59977, 384)\n",
            "train_inputs: (59977, 384)\n",
            "train_labels: (59977,)\n",
            "train_labels: (59977,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4ccdae174e545d69225ce8be22d4b53",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Loading ...: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_discard: 78\n",
            "dev_inputs: (5696, 384)\n",
            "dev_inputs: (5696, 384)\n",
            "dev_labels: (5696,)\n",
            "dev_labels: (5696,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[    5, 15798,    10, ...,     0,     0,     0],\n",
              "         [    5, 15798,    10, ...,     0,     0,     0],\n",
              "         [    5, 15798,    19, ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [    5, 21666,    19, ...,     0,     0,     0],\n",
              "         [    5,   964, 16865, ...,     0,     0,     0],\n",
              "         [    5,   365,    15, ...,     0,     0,     0]]),\n",
              "  array([[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]])),\n",
              " (array([ 37, 184,  98, ...,  74, 190,  35]),\n",
              "  array([ 37, 185, 102, ...,  75, 191,  44])))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JHLDhItb0pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfbcdc3-977a-4d4c-c2dd-ed907d8bc9b1"
      },
      "source": [
        "# Question과 Context가 포함된 입력데이터 1번째\n",
        "train_inputs[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    5, 15798,    10, 28935,     9,    11, 29566,    20, 14604,\n",
              "       20424,  3904,    70,    11,  4648,    10,    19,  1910,     4,\n",
              "       22070,    15, 15798,    10, 28935,     9,    11, 29566,    16,\n",
              "         626, 14604,    38, 14028, 11773, 13829,   384,  8376,  3021,\n",
              "        1239,  6874,    16,  1687,  5958,  2694,  5061,     7,    30,\n",
              "        1613, 15798,    10, 28065,    75,  4415,  1816,  4978,    27,\n",
              "         347,   145,   107,  2703,   263,    11,     1,    18,  5853,\n",
              "          99,  9677,    24, 11969,    13,  7595,   437,  1019,  5907,\n",
              "         257,  3794,  1972,    20, 11278,    11, 29566,     9,   612,\n",
              "       12631, 13214,  1732,    76,     7,   110,  8802, 17581,   354,\n",
              "        9648,  2060,    21,  1682, 22110, 18164,    17, 21076, 14980,\n",
              "           9,  6874,    81, 11325,  4239,  3597,  1010,  1035, 17670,\n",
              "           8,  2447,  1306,    35,   443,    11, 29566,     9,   315,\n",
              "       12729, 14457,    30,  7938,  3742, 10766,   634,  9971, 17590,\n",
              "       19424,    10,   285,  4080,    61, 17573,   483,     7,  7588,\n",
              "           9,   473,   338,   147,  1924,     9, 11016,   136,  1034,\n",
              "          13, 11672,    40,  3436,  5217,  7898, 11684,    57,   830,\n",
              "           9,    19,  3319,    86,   220,   464, 14980,     9, 20515,\n",
              "         412,   991,   684,  1924,     9,   634,   920,   144,   430,\n",
              "          34,    25,     7,  4210,  6874,  2150,    16, 22070,   298,\n",
              "        1159,    75,  1098,  8802,  7490,   805,    35, 18678,    16,\n",
              "        1657,  1970,  2272,    53,     7,   110,  6559,  2178,    24,\n",
              "         756,    82,    30,   315,   684,  3772, 18678,    12,    16,\n",
              "        1682, 22110,     9, 22469,    22,  1757,    61,  8817,   194,\n",
              "         164,  1693,   749,     8,  6739, 12202,    10,   494,     7,\n",
              "         502, 12181,    18,    46,    15,   374,    17,  1680,   708,\n",
              "       26344,    22,  1757,   432,   465,   351,    32, 18563,   710,\n",
              "           8,  2585,  1384, 16071,   265,  3360,     7,    38,   747,\n",
              "          82,   383,   678,   200,    26,   590,  1281,    41,  1172,\n",
              "          31,    16,  2178,    43,  3044,   156,    17,   647,   468,\n",
              "        7490,    41,    84,   758,    92,    33,  3401,   369, 18319,\n",
              "           8,  2582, 29798,  1102,    17,    30,  4573, 11170,   139,\n",
              "          58,   220,   773,    19,   211, 23824,    25,     7,     4,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIzLaPCjb0pY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3a5382-f1db-4fd6-e826-18be2200ee0c"
      },
      "source": [
        "# Question을 0으로, Context를 1로 구분해 준 Segment 데이터 1번째\n",
        "train_inputs[1][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb_sGaWgb0pY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f28972-f7a4-42f4-91d0-e7d617603c1c"
      },
      "source": [
        "# Answer위치의 시작점과 끝점 라벨 1번째\n",
        "train_labels[0][0], train_labels[1][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMwFGgZYb0pY"
      },
      "source": [
        "# Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkFRwxW3b0pY"
      },
      "source": [
        "# 유틸리티 함수들\n",
        "\n",
        "def get_pad_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    pad mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: pad mask (pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
        "    mask = tf.expand_dims(mask, axis=1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_ahead_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    ahead mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    n_seq = tf.shape(tokens)[1]\n",
        "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
        "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
        "    pad_mask = get_pad_mask(tokens, i_pad)\n",
        "    mask = tf.maximum(ahead_mask, pad_mask)\n",
        "    return mask\n",
        "\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    gelu activation 함수\n",
        "    :param x: 입력 값\n",
        "    :return: gelu activation result\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
        "\n",
        "\n",
        "def kernel_initializer(stddev=0.02):\n",
        "    \"\"\"\n",
        "    parameter initializer 생성\n",
        "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
        "    \"\"\"\n",
        "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
        "\n",
        "\n",
        "def bias_initializer():\n",
        "    \"\"\"\n",
        "    bias initializer 생성\n",
        "    \"\"\"\n",
        "    return tf.zeros_initializer\n",
        "\n",
        "\n",
        "class Config(dict):\n",
        "    \"\"\"\n",
        "    json을 config 형태로 사용하기 위한 Class\n",
        "    :param dict: config dictionary\n",
        "    \"\"\"\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        \"\"\"\n",
        "        file에서 Config를 생성 함\n",
        "        :param file: filename\n",
        "        \"\"\"\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UuLOhUKb0pZ"
      },
      "source": [
        "# mode == \"embedding\" 일 경우 Token Embedding Layer 로 사용되는 layer 클래스입니다. \n",
        "\n",
        "class SharedEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Weighed Shared Embedding Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.n_vocab = config.n_vocab\n",
        "        self.d_model = config.d_model\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        shared weight 생성\n",
        "        :param input_shape: Tensor Shape (not used)\n",
        "        \"\"\"\n",
        "        with tf.name_scope(\"shared_embedding_weight\"):\n",
        "            self.shared_weights = self.add_weight(\n",
        "                \"weights\",\n",
        "                shape=[self.n_vocab, self.d_model],\n",
        "                initializer=kernel_initializer()\n",
        "            )\n",
        "\n",
        "    def call(self, inputs, mode=\"embedding\"):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: 입력\n",
        "        :param mode: 실행 모드\n",
        "        :return: embedding or linear 실행 결과\n",
        "        \"\"\"\n",
        "        # mode가 embedding일 경우 embedding lookup 실행\n",
        "        if mode == \"embedding\":\n",
        "            return self._embedding(inputs)\n",
        "        # mode가 linear일 경우 linear 실행\n",
        "        elif mode == \"linear\":\n",
        "            return self._linear(inputs)\n",
        "        # mode가 기타일 경우 오류 발생\n",
        "        else:\n",
        "            raise ValueError(f\"mode {mode} is not valid.\")\n",
        "    \n",
        "    def _embedding(self, inputs):\n",
        "        \"\"\"\n",
        "        embedding lookup\n",
        "        :param inputs: 입력\n",
        "        \"\"\"\n",
        "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
        "        return embed\n",
        "\n",
        "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
        "        \"\"\"\n",
        "        linear 실행\n",
        "        :param inputs: 입력\n",
        "        \"\"\"\n",
        "        n_batch = tf.shape(inputs)[0]\n",
        "        n_seq = tf.shape(inputs)[1]\n",
        "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
        "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
        "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYHJaQq9b0pZ"
      },
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Positional Embedding Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"position_embedding\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: 입력\n",
        "        :return embed: positional embedding lookup 결과\n",
        "        \"\"\"\n",
        "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
        "        embed = self.embedding(position)\n",
        "        return embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BgpzB08b0pZ"
      },
      "source": [
        "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Scale Dot Product Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param Q: Q value\n",
        "        :param K: K value\n",
        "        :param V: V value\n",
        "        :param attn_mask: 실행 모드\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
        "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
        "        attn_scale = tf.math.divide(attn_score, scale)\n",
        "        attn_scale -= 1.e9 * attn_mask\n",
        "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
        "        attn_out = tf.matmul(attn_prob, V)\n",
        "        return attn_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3azJj9q8b0pZ"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Multi Head Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"multi_head_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.d_model = config.d_model\n",
        "        self.n_head = config.n_head\n",
        "        self.d_head = config.d_head\n",
        "\n",
        "        # Q, K, V input dense layer\n",
        "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        # Scale Dot Product Attention class\n",
        "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
        "        # output dense layer\n",
        "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param Q: Q value\n",
        "        :param K: K value\n",
        "        :param V: V value\n",
        "        :param attn_mask: 실행 모드\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        # reshape Q, K, V, attn_mask\n",
        "        batch_size = tf.shape(Q)[0]\n",
        "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
        "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
        "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
        "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
        "        # transpose and liner\n",
        "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
        "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
        "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
        "\n",
        "        return attn_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jwjvn1ib0pa"
      },
      "source": [
        "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Position Wise Feed Forward Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"feed_forward\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: inputs\n",
        "        :return ff_val: feed forward 실행 결과\n",
        "        \"\"\"\n",
        "        ff_val = self.W_2(self.W_1(inputs))\n",
        "        return ff_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sPGFKCLb0pa"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Encoder Layer Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"encoder_layer\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.self_attention = MultiHeadAttention(config)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "\n",
        "        self.ffn = PositionWiseFeedForward(config)\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        " \n",
        "    def call(self, enc_embed, self_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
        "        :param self_mask: enc_tokens의 pad mask\n",
        "        :return enc_out: EncoderLayer 실행 결과\n",
        "        \"\"\"\n",
        "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
        "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
        "\n",
        "        ffn_val = self.ffn(norm1_val)\n",
        "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
        "\n",
        "        return enc_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLWeiIBZb0pa"
      },
      "source": [
        "class BERT(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    BERT Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"bert\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.i_pad = config.i_pad\n",
        "        self.embedding = SharedEmbedding(config)\n",
        "        self.position = PositionalEmbedding(config)\n",
        "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "        \n",
        "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        "\n",
        "    def call(self, enc_tokens, segments):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param enc_tokens: encoder tokens\n",
        "        :param segments: token segments\n",
        "        :return logits_cls: CLS 결과 logits\n",
        "        :return logits_lm: LM 결과 logits\n",
        "        \"\"\"\n",
        "        enc_self_mask = get_pad_mask(enc_tokens, self.i_pad)\n",
        "\n",
        "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
        "\n",
        "        enc_out = self.dropout(enc_embed)\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
        "\n",
        "        logits_cls = enc_out[:,0]\n",
        "        logits_lm = enc_out\n",
        "        return logits_cls, logits_lm\n",
        "    \n",
        "    def get_embedding(self, tokens, segments):\n",
        "        \"\"\"\n",
        "        token embedding, position embedding lookup\n",
        "        :param tokens: 입력 tokens\n",
        "        :param segments: 입력 segments\n",
        "        :return embed: embedding 결과\n",
        "        \"\"\"\n",
        "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
        "        embed = self.norm(embed)\n",
        "        return embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCK1TAX9b0pa"
      },
      "source": [
        "class BERT4KorQuAD(tf.keras.Model):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(name='BERT4KorQuAD')\n",
        "\n",
        "        self.bert = BERT(config)\n",
        "        self.dense = tf.keras.layers.Dense(2)\n",
        "    \n",
        "    def call(self, enc_tokens, segments):\n",
        "        logits_cls, logits_lm = self.bert(enc_tokens, segments)\n",
        "\n",
        "        hidden = self.dense(logits_lm) # (bs, n_seq, 2)\n",
        "        start_logits, end_logits = tf.split(hidden, 2, axis=-1)  # (bs, n_seq, 1), (bs, n_seq, 1)\n",
        "\n",
        "        start_logits = tf.squeeze(start_logits, axis=-1)\n",
        "        start_outputs = tf.keras.layers.Softmax(name=\"start\")(start_logits)\n",
        "\n",
        "        end_logits = tf.squeeze(end_logits, axis=-1)\n",
        "        end_outputs = tf.keras.layers.Softmax(name=\"end\")(end_logits)\n",
        "\n",
        "        return start_outputs, end_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpv7E4kxb0pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f987aab7-47a3-4ac6-f3a0-7ccb8b70a871"
      },
      "source": [
        "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 384, \"n_vocab\": 0, \"i_pad\": 0})\n",
        "config.n_vocab = len(vocab)\n",
        "config.i_pad = vocab.pad_id()\n",
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'d_ff': 1024,\n",
              " 'd_head': 64,\n",
              " 'd_model': 256,\n",
              " 'dropout': 0.1,\n",
              " 'i_pad': 0,\n",
              " 'layernorm_epsilon': 0.001,\n",
              " 'n_head': 4,\n",
              " 'n_layer': 3,\n",
              " 'n_seq': 384,\n",
              " 'n_vocab': 32007}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt9u8MlOb0pb"
      },
      "source": [
        "bert_batch_size = 32 \n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels)).shuffle(10000).batch(bert_batch_size)\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((dev_inputs, dev_labels)).batch(bert_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOnM0QI0b0pb"
      },
      "source": [
        "model = BERT4KorQuAD(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZPKg6utb0pb"
      },
      "source": [
        "def train_epoch(model, dataset, loss_fn, acc_fn, optimizer):\n",
        "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
        "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
        "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
        "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
        "\n",
        "    p_bar = tqdm(dataset)\n",
        "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(p_bar):\n",
        "        with tf.GradientTape() as tape:\n",
        "            start_outputs, end_outputs = model(enc_tokens, segments)\n",
        "\n",
        "            start_loss = loss_fn(start_labels, start_outputs)\n",
        "            end_loss = loss_fn(end_labels, end_outputs)\n",
        "            loss = start_loss + end_loss\n",
        "\n",
        "            start_acc = acc_fn(start_labels, start_outputs)\n",
        "            end_acc = acc_fn(end_labels, end_outputs)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        metric_start_loss(start_loss)\n",
        "        metric_end_loss(end_loss)\n",
        "        metric_start_acc(start_acc)\n",
        "        metric_end_acc(end_acc)\n",
        "        if batch % 10 == 9:\n",
        "            p_bar.set_description(f'loss: {metric_start_loss.result():0.4f}, {metric_end_loss.result():0.4f}, acc: {metric_start_acc.result():0.4f}, {metric_end_acc.result():0.4f}')\n",
        "    p_bar.close()\n",
        "\n",
        "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INVlH2h8b0pb"
      },
      "source": [
        "def eval_epoch(model, dataset, loss_fn, acc_fn):\n",
        "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
        "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
        "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
        "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
        "\n",
        "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(dataset):\n",
        "        start_outputs, end_outputs = model(enc_tokens, segments)\n",
        "\n",
        "        start_loss = loss_fn(start_labels, start_outputs)\n",
        "        end_loss = loss_fn(end_labels, end_outputs)\n",
        "\n",
        "        start_acc = acc_fn(start_labels, start_outputs)\n",
        "        end_acc = acc_fn(end_labels, end_outputs)\n",
        "\n",
        "        metric_start_loss(start_loss)\n",
        "        metric_end_loss(end_loss)\n",
        "        metric_start_acc(start_acc)\n",
        "        metric_end_acc(end_acc)\n",
        "\n",
        "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj1PXoYUb0pb"
      },
      "source": [
        "history_start_loss = []\n",
        "history_end_loss = []\n",
        "history_start_accuracy = []\n",
        "history_end_accuracy = []\n",
        "\n",
        "history_val_start_loss = []\n",
        "history_val_end_loss = []\n",
        "history_val_start_accuracy = []\n",
        "history_val_end_accuracy = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MybnCtuob0pb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "d29ad379512f46edab9d9656ad8a6d58",
            "e946348b1c9a4844a12e26e8327da904",
            "f2c8069f0fed4bf99c33cc9263021fea",
            "a997337ceaab4994968b68cf0e82f7df",
            "2def78c56616487e878bf470b8befbc4",
            "22054c1667c249ae99205a8d8167ae08",
            "c00567f2bf94439bb55b6f9fc2bd589e",
            "61c7ace3ed414e5ca9712a210d6401c4",
            "6edd0e956edb4fc5bbf35d50b551da70",
            "207e817a7b6f46bda092f98ce2a27a11",
            "036c2d8fb316473aba8bbfc07ad39de4"
          ]
        },
        "outputId": "28b4cc99-803d-4682-a478-bba0f37aa2d6"
      },
      "source": [
        "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
        "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
        "\n",
        "best_acc = .0\n",
        "patience = 0\n",
        "for epoch in range(20):\n",
        "    sl, el, sa, ea = train_epoch(model, train_dataset, loss_fn, acc_fn, optimizer)\n",
        "    history_start_loss.append(sl)\n",
        "    history_end_loss.append(el)\n",
        "    history_start_accuracy.append(sa)\n",
        "    history_end_accuracy.append(ea)\n",
        "    \n",
        "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model, dev_dataset, loss_fn, acc_fn)\n",
        "    history_val_start_loss.append(start_loss)\n",
        "    history_val_end_loss.append(end_loss)\n",
        "    history_val_start_accuracy.append(start_acc)\n",
        "    history_val_end_accuracy.append(end_acc)\n",
        "    \n",
        "    print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
        "    acc = start_acc + end_acc\n",
        "    if best_acc < acc:\n",
        "        patience = 0\n",
        "        best_acc = acc\n",
        "        model.save_weights(os.path.join(data_dir, \"korquad_bert_none_pretrain.hdf5\"))\n",
        "        print(f'save best model')\n",
        "    else:\n",
        "        patience += 1\n",
        "    if 5 <= patience:\n",
        "        print(f'early stopping')\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d29ad379512f46edab9d9656ad8a6d58",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1875 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-fb78a81869ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mhistory_start_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhistory_end_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-e47c009a4871>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataset, loss_fn, acc_fn, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mstart_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mend_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_GatherGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   2190\u001b[0m   \u001b[0mvalues_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m   \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m   \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8389\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8390\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 8391\u001b[0;31m         _ctx, \"Reshape\", name, tensor, shape)\n\u001b[0m\u001b[1;32m   8392\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8393\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "674Q-V6Kb0pc"
      },
      "source": [
        "# Pretrained Model 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es6TggPrb0pc"
      },
      "source": [
        "## STEP 1. pretrained model 로딩하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-6wzeAPb0pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50638f2-5a3f-427d-ef76-caf1dc018b08"
      },
      "source": [
        "checkpoint_file = os.path.join(model_dir, 'bert_pretrain_32000.hdf5')\n",
        "\n",
        "model = BERT4KorQuAD(config)\n",
        "\n",
        "if os.path.exists(checkpoint_file):\n",
        "    #  pretrained model 을 로드하기 위해 먼저 모델이 생성되어 있어야 한다.\n",
        "    enc_tokens = np.random.randint(0, len(vocab), (4, 10))\n",
        "    segments = np.random.randint(0, 2, (4, 10))\n",
        "    model(enc_tokens, segments)\n",
        "    \n",
        "    # checkpoint 파일로부터 필요한 layer를 불러온다. \n",
        "    model.load_weights(os.path.join(model_dir, \"bert_pretrain_32000.hdf5\"), by_name=True)\n",
        "\n",
        "    model.summary()\n",
        "else:\n",
        "    print('NO Pretrained Model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"BERT4KorQuAD\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (BERT)                  multiple                  10662400  \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             multiple                  514       \n",
            "=================================================================\n",
            "Total params: 10,662,914\n",
            "Trainable params: 10,662,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQaVaFZlb0pc"
      },
      "source": [
        "## STEP 2. pretrained model finetune 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8zzP9dEb0pd"
      },
      "source": [
        "# history_start_loss_pretrained = []\n",
        "# history_end_loss_pretrained = []\n",
        "# history_start_accuracy_pretrained = []\n",
        "# history_end_accuracy_pretrained = []\n",
        "\n",
        "# history_val_start_loss_pretrained = []\n",
        "# history_val_end_loss_pretrained = []\n",
        "# history_val_start_accuracy_pretrained = []\n",
        "# history_val_end_accuracy_pretrained = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHnXCsnMb0pd"
      },
      "source": [
        "# loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
        "# acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
        "\n",
        "# best_acc = .0\n",
        "# patience = 0\n",
        "# for epoch in range(20):\n",
        "#     slp, elp, sap, eap = train_epoch(model, train_dataset, loss_fn, acc_fn, optimizer)\n",
        "#     history_start_loss_pretrained.append(slp)\n",
        "#     history_end_loss_pretrained.append(elp)\n",
        "#     history_start_accuracy_pretrained.append(sap)\n",
        "#     history_end_accuracy_pretrained.append(eap)\n",
        "    \n",
        "#     start_loss, end_loss, start_acc, end_acc = eval_epoch(model, dev_dataset, loss_fn, acc_fn)\n",
        "#     history_val_start_loss_pretrained.append(start_loss)\n",
        "#     history_val_end_loss_pretrained.append(end_loss)\n",
        "#     history_val_start_accuracy_pretrained.append(start_acc)\n",
        "#     history_val_end_accuracy_pretrained.append(end_acc)\n",
        "    \n",
        "#     print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
        "#     acc = start_acc + end_acc\n",
        "#     if best_acc < acc:\n",
        "#         patience = 0\n",
        "#         best_acc = acc\n",
        "#         model.save_weights(os.path.join(data_dir, \"korquad_bert_none_pretrain.hdf5\"))\n",
        "#         print(f'save best model')\n",
        "#     else:\n",
        "#         patience += 1\n",
        "#     if 5 <= patience:\n",
        "#         print(f'early stopping')\n",
        "#         break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4puNt5tEb0pd"
      },
      "source": [
        "## STEP 3. Inference 수행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od3kTs0Qb0pd"
      },
      "source": [
        "def do_predict(model, question, context):\n",
        "    \"\"\"\n",
        "    입력에 대한 답변 생성하는 함수\n",
        "    :param model: model\n",
        "    :param question: 입력 문자열\n",
        "    :param context: 입력 문자열\n",
        "    \"\"\"\n",
        "    q_tokens = vocab.encode_as_pieces(question)[:args.max_query_length]\n",
        "    c_tokens = vocab.encode_as_pieces(context)[:args.max_seq_length - len(q_tokens) - 3]\n",
        "    tokens = ['[CLS]'] + q_tokens + ['[SEP]'] + c_tokens + ['[SEP]']\n",
        "    token_ids = [vocab.piece_to_id(token) for token in tokens]\n",
        "    segments = [0] * (len(q_tokens) + 2) + [1] * (len(c_tokens) + 1)\n",
        "\n",
        "    y_start, y_end = model(np.array([token_ids]), np.array([segments]))\n",
        "    # print(y_start, y_end)\n",
        "    y_start_idx = K.argmax(y_start, axis=-1)[0].numpy()\n",
        "    y_end_idx = K.argmax(y_end, axis=-1)[0].numpy()\n",
        "    answer_tokens = tokens[y_start_idx:y_end_idx + 1]\n",
        "\n",
        "    return vocab.decode_pieces(answer_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ2pzaOob0pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf21808-7b8f-4bb6-b395-f51d2031c8e6"
      },
      "source": [
        "dev_json = os.path.join(data_dir, \"korquad_dev.json\")\n",
        "\n",
        "with open(dev_json) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        data = json.loads(line)\n",
        "        question = vocab.decode_pieces(data['question'])\n",
        "        context = vocab.decode_pieces(data['context'])\n",
        "        answer = data['answer']\n",
        "        answer_predict = do_predict(model, question, context)\n",
        "        if answer in answer_predict:\n",
        "            print(i)\n",
        "            print(\"질문 : \", question)\n",
        "            print(\"지문 : \", context)\n",
        "            print(\"정답 : \", answer)\n",
        "            print(\"예측 : \", answer_predict, \"\\n\")\n",
        "        if 100 < i:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "질문 :  미국 군대 내 두번째로 높은 직위는 무엇인가?\n",
            "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
            "정답 :  미국 육군 부참모 총장\n",
            "예측 :  리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《 \n",
            "\n",
            "47\n",
            "질문 :  노아의 방주는 총 몇층으로 되어 있었는가?\n",
            "지문 :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), 폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
            "정답 :  3층\n",
            "예측 :  1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방 \n",
            "\n",
            "63\n",
            "질문 :  노아의 방주가 역사적으로 실재했다는 주장은 무엇이 존재하지 않아 학계로부터 전혀 인정받지 못하고 있는가?\n",
            "지문 :  물론 노아의 방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. 모든 과학관련 학계에서는 노아의 방주의 구조나 재질등이 실제로 존재할 수 없는 설화속 이야기라는 데에 동의하고 있다.\n",
            "정답 :  증거\n",
            "예측 :  중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. 모든 과학관련 학계에서는 노아의 방주의 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}